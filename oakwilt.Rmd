---
title: "OakWilt"
author: "Emily Giroux"
date: "9/30/2020"
output:
  pdf_document: default
  html_document: default
urlcolor: blue
header-includes: \usepackage{xcolor}
---

```{r, global_options, eval=TRUE, echo=FALSE}
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff = 80), tidy = TRUE, fig.align = 'center',
               cache = FALSE, collapse = TRUE, echo = FALSE, eval = FALSE, include = FALSE,
               message = FALSE, quietly = TRUE, results = 'hide', warn.conflicts = FALSE, 
               warning = FALSE)
```

**Using package `BiocManager` to install required packages:**
```{r, biocInstall, eval=TRUE, echo=TRUE, include=TRUE}
#Installing required packages
r <- getOption("repos")
r["CRAN"] <- "http://cran.us.r-project.org"
options(repos = r)

if (!requireNamespace("BiocManager"))
    install.packages("BiocManager")
BiocManager::install()

library("BiocManager")
.cran_packages <- c("data.table", "kableExtra", "knitr", "rprojroot")
.bioc_packages <- c("BiocStyle", "Biostrings", "dada2", "RAM")
.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
  BiocManager::install(.bioc_packages[!.inst], ask = FALSE)
}
```
   
**Load packages into session, and print package versions:**
```{r, showBiocPackages, echo=TRUE, eval=TRUE, include=TRUE, results='hold'}
sapply(c(.cran_packages, .bioc_packages), require, character.only = TRUE)
```
**Source our custom R scripts:**    
For this we will use the rprojroot package to set the directory structures. This will help us when finding our files to source functions. We specify ours is an RStudio project. The root object contains a function that will help us locate our package R files regarless of our current working directory.
```{r sourcing_my_functions, echo=TRUE, eval=TRUE, include=TRUE, tidy=FALSE}
library("rprojroot")
root        <- rprojroot::is_rstudio_project
scriptsPath <- root$make_fix_file(".")("R")
scripts     <- dir(root$find_file("R", path = root$find_file()))
scriptsl    <- paste(scriptsPath, scripts, sep = "/")
lapply(scriptsl, source)
```

Setting up working directories:
```{r}
sharedPath <- "/isilon/cfia-ottawa-fallowfield/users/girouxeml/PIRL_working_directory"
analysis <- "oakwilt"
sharedPathAn <- paste(sharedPath, analysis, sep = "/")
dir.create(sharedPathAn, showWarnings = TRUE, recursive = FALSE)
imageDirPath <- "/home/CFIA-ACIA/girouxeml/GitHub_Repos/r_environments/oakwilt/"
dir.create("/home/CFIA-ACIA/girouxeml/GitHub_Repos/r_environments/oakwilt", 
           showWarnings = TRUE, recursive = FALSE)
baseImage <- "oakwilt.RData"
save.image(paste(imageDirPath, baseImage, sep = ""))
```
Quick image load:
```{r}
imageDirPath <- "/home/CFIA-ACIA/girouxeml/GitHub_Repos/r_environments/oakwilt/"
baseImage <- "oakwilt.RData"
load(paste(imageDirPath, baseImage, sep = ""))
```
### Step 1:       
Set up all folders (baseDir, qiime2, trimmed, logs)     
```{r}
library("data.table")
rawDataDir <- "/isilon/cfia-ottawa-fallowfield/users/girouxeml/data/forMarco"
compressedFiles <- list.files(rawDataDir, pattern = "*.bz2", full.names = TRUE)
metadata <- as.data.table(cbind(compressedFiles))
metadata$rawFileName <- basename(metadata$compressedFiles)
metadata$basename <- gsub(".tar.bz2", "", metadata$rawFileName)
rawDataWorkingPath <- paste(sharedPathAn, "rawData", sep = "/")
dir.create(rawDataWorkingPath, showWarnings = TRUE, recursive = FALSE)
metadata$rawWorkingPath <- paste(rawDataWorkingPath, metadata$basename, sep = "/")

for(i in 1:nrow(metadata)){
  cmd[i] <- paste("mkdir -p ",  rawDataWorkingPath, " && tar -xvjf ", metadata$compressedFiles[i], 
                  " -C ", rawDataWorkingPath, sep = "")  
  system(cmd[i])
}

metadataITSF_files <- list.files(rawDataWorkingPath, pattern = "ITSF", recursive = TRUE, full.names = TRUE)
metadataITSF <- as.data.table(cbind(metadataITSF_files))
metadataITSF$basename <- basename(metadataITSF$metadataITSF_files)
metadataITSF$barcode <- gsub(".*ITS1F_", "", metadataITSF$basename)
metadataITSF$barcode <- gsub(".fastq", "", metadataITSF$barcode)
metadataITSF$barcode <- gsub("b", "B", metadataITSF$barcode)

metadataITS2R_files <- list.files(rawDataWorkingPath, pattern = "ITS2rev", recursive = TRUE, full.names = TRUE)
metadataITS2R <- as.data.table(cbind(metadataITS2R_files))
metadataITS2R$basename <- basename(metadataITS2R$metadataITS2R_files)
metadataITS2R$barcode <- gsub(".*ITS2_A_", "", metadataITS2R$basename)
metadataITS2R$barcode <- gsub(".fastq", "", metadataITS2R$barcode)

# Join the metadata samples from the forward and reverse tables using the common barcode to join rows:
setkey(metadataITSF, barcode)
setkey(metadataITS2R, barcode)

metadataITS <- merge(metadataITSF, metadataITS2R, all.x = TRUE)
setnames(metadataITS, "basename.x", "fwdFastq")
setnames(metadataITS, "basename.y", "revFastq")
metadataITS <- na.omit(metadataITS)
```

Prepare file directories:    
Qiime2     
# Input folder     
export fastq=/media/30tb_raid10/data/PIRL/2020-01-15_OAK_ITSF_30     
# Output folder     
export baseDir=/media/2TB_NVMe/pirl_2020-01-15_ITS1F     
     
        
Mimicking Marc-o's file directroy structure:    
baseDir <- sharedPathAn     
qiime2 <- paste(sharedPathAn, "qiime2", sep = "/")     
trimmed <- paste(sharedPathAn, "trimmed", sep = "/")     
logs <- paste(sharedPathAn, "logs", sep = "/")     
```{r}
# Make a directory for the trimmed data
trimmedData <- paste(sharedPathAn, "trimmed", sep = "/")
dir.create(trimmedData, showWarnings = TRUE, recursive = FALSE)

# Make a directory to hold the log files generated by itsxpress:
itsxpressLogs <- paste(sharedPathAn, "logs/itsxpress", sep = "/")
dir.create(itsxpressLogs, showWarnings = TRUE, recursive = TRUE)

qiime2Dir <- paste(sharedPathAn, "qiime2", sep = "/")
dir.create(qiime2Dir, showWarnings = TRUE, recursive = FALSE)
```

### Step 2:       
Retrieve ITS1 part of the amplicons using ITSxpress (includes trimming regions and export)      
Run ITSxpress on the raw fastq reads:   
     
**Note:** For the ITS2 region, itsxpress does not recognise the ITS2 amplicon regions and nothing is returned - no OTU table for ITS2 can be generated. Marco is looking into this issue to see if there is a sequence pattern at the ends that is inhibiting the correct processing of the sequences by itsxpress?? Possible overfitlering?? Direct checing of the sequences shows us that the ITS2 regions are in fact present, and there are many sequences observed. Problem appears to be random, and has worked with some sets of data but not others.... possible barcode issue??    
```{r}
prefix <- "ITSxpress_ITSF"
cmd <- paste("conda activate qiime2-2020.8 && itsxpress ",  
             " --fastq ", metadataITS$metadataITSF_files, 
             " --single_end ",
             " --outfile ", paste(trimmedData, "/ITSF_trimmed.", metadataITS$barcode, ".fastq", sep = ""),
             " --region ITS1 --taxa Fungi --cluster_id 0.995 ",
             " --log ", paste(itsxpressLogs, "/ITSF_trimmed.", metadataITS$barcode, ".log", sep = ""),
             " && conda deactivate ",
             sep = "")  
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```
**To remove the output files after you are done:**
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Running itsxpress on the itsf b56 reads separately, since they do not have a pair with the reverse reads for this barcode and are therefore not in the final metadataITS table, maybe they should be there?
```{r}
cmd <- paste("itsxpress ",  
             " --fastq ", metadataITSF$metadataITSF_files[56], 
             " --single_end ",
             " --outfile ", paste(trimmedData, "/ITSF_trimmed.", metadataITSF$barcode[56], ".fastq", sep = ""),
             " --region ITS1 --taxa Fungi --cluster_id 0.995 ",
             " --log ", paste(itsxpressLogs, "/ITSF_trimmed.", metadataITSF$barcode[56], ".log", sep = ""),
             sep = "")  
# Run the above command directly on the command line, since it's just for one file and shouldn't take long.
```

Add the path to the trimmed fastq files and a column to set unique sample names based on the filename/sequencing run and sample barcode number:
```{r}
metadataITSF$trimmedPath <- paste(trimmedData, "/ITSF_trimmed.", metadataITSF$barcode, ".fastq", sep = "")
metadataITSF$SampleID <- paste("ITSF_OAK_2019Plate1", metadataITSF$barcode, sep = "_")
```

Create a manifest file that qiime2 will use to import our fastq data and write it to a tsv file:
```{r}
library("data.table")
manifest <- metadataITSF[, .('sample-id' = SampleID, 'absolute-filepath' = trimmedPath)]

write.table(manifest, file = paste(sharedPathAn, "qiime2_import_manifest.tsv", sep = "/"), 
            quote = FALSE, sep = "\t", row.names = FALSE, col.names = TRUE)
```

# import fastq files
qiime tools import \
    --type 'SampleData[SequencesWithQuality]' \
    --input-path "${baseDir}"/fastq \
    --output-path "${baseDir}"/qiime2/demux-single-end.qza \
    --input-format CasavaOneEightSingleLanePerSampleDirFmt
```{r}
prefix <- "qiimeImport"
cmd <- paste("conda activate qiime2-2020.8 && ",
             "qiime tools import ",
             " --type 'SampleData[SequencesWithQuality]' ",
             " --input-path ", paste(sharedPathAn, "qiime2_import_manifest.tsv", sep = "/"),
             " --output-path ", paste(qiime2Dir, "/demux-single-end.qza", sep = ""),
             " --input-format SingleEndFastqManifestPhred33V2 ",
             " && conda deactivate ", sep = "")
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```
Create a file to visualise the qiime2 fastq files imported:
```{r}
prefix <- "qiimeVisualiseImport"
cmd <- paste("conda activate qiime2-2020.8 && ",
             " qiime demux summarize ",
             " --i-data  ", paste(qiime2Dir, "/demux-single-end.qza", sep = ""),
             " --o-visualization ", paste(qiime2Dir, "/demux-single-end.qzv", sep = ""),
             " --verbose ", 
             " && conda deactivate ", sep = "")
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```
To view demux-single-end.qzv, open https://view.qiime2.org/ with your browser and drag the file into the window at the top of the page.     
    
**To remove the output files after you are done:**
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Denoise the sequences with dada2 within qiime2:    
- corrects sequencing errors    
- removes chimeras    
- clusters sequences at 100% similarity    
- outputs an asv table and the representative sequences
```{r}
prefix <- "qiimeDADA2deNoiseSingle"
cmd <- paste("conda activate qiime2-2020.8 && ",
             " qiime dada2 denoise-single ",
             " --i-demultiplexed-seqs ", paste(qiime2Dir, "/demux-single-end.qza", sep = ""),
             " --p-trim-left 0 ",
             " --p-trunc-len 0 ",
             " --o-representative-sequences ", paste(qiime2Dir, "/rep-seqs-dada2.qza", sep = ""),
             " --o-table ", paste(qiime2Dir, "/table-dada2.qza", sep = ""),
             " --o-denoising-stats ", paste(qiime2Dir, "/stats-dada2.qza", sep = ""),
             " --p-n-threads 20 ", 
             " --verbose ", 
             " && conda deactivate ", sep = "")
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```
Export the dada2 results:    
```{r}
# Export ASV (OTU-like table) table
prefix <- "qiimeExport"
cmd <- paste("conda activate qiime2-2020.8 && ",
             " mkdir ", paste(sharedPathAn, "phyloseq", sep = "/"),
             " && qiime tools export ",
             " --input-path ", paste(qiime2Dir, "/table-dada2.qza", sep = ""),
             " --output-path ", paste(sharedPathAn, "phyloseq", sep = "/"),
             " && conda deactivate ", sep = "")
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

```{r}
# Convert biom format to tsv format
prefix <- "qiimeBiomConvert"
cmd <- paste("conda activate qiime2-2020.8 && ",
             " biom convert ",
             " -i ", paste(sharedPathAn, "phyloseq", "feature-table.biom", sep = "/"), 
             " -o ", paste(sharedPathAn, "phyloseq", "otu_table.tsv", sep = "/"),
             " --to-tsv && cd ", paste(sharedPathAn, "phyloseq", sep = "/"),
             " && sed -i '1d' otu_table.tsv && sed -i 's/#OTU ID//' otu_table.tsv && cd .. ",
             " && conda deactivate ", sep = "")
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

```{r}
# Export representative sequences
prefix <- "qiimeRepSeqsExport"
cmd <- paste("conda activate qiime2-2020.8 && ",
             " qiime tools export ",
             " --input-path ", paste(qiime2Dir, "/rep-seqs-dada2.qza", sep = ""),
             " --output-path ", paste(sharedPathAn, "phyloseq", sep = "/"),
             " && conda deactivate ", sep = "")
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```


Set up the qiime2 UNITE database using UNITE 2018-2019 that Marc-o used:
```{r}
uniteDBDir2019 <- "/isilon/cfia-ottawa-fallowfield/users/girouxeml/Databases/UNITE_2018-11-18_qiimeReleaseDB"
```

```{r}
# Import the UNITE reference sequences into QIIME2.
prefix <- "qiimeUniteImport"
cmd <- paste("conda activate qiime2-2020.8 && ",
             " qiime tools import ",
             " --type FeatureData[Sequence] ",
             " --input-path ", paste(uniteDBDir2019, "sh_refs_qiime_ver8_99_02.02.2019.fasta", sep = "/"),
             " --output-path ", paste(sharedPathAn, "phyloseq", "unite-ver8_99_02.02.2019.qza", sep = "/"),
             " && conda deactivate ", sep = "")
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```


```{r}
# Import the taxonomy file.
prefix <- "qiimeTaxUniteImport"
cmd <- paste("conda activate qiime2-2020.8 && ",
             " qiime tools import ",
             " --type FeatureData[Taxonomy] ",
             " --input-path ", paste(uniteDBDir2019, "sh_taxonomy_qiime_ver8_99_02.02.2019.txt", sep = "/"),
             " --output-path ", paste(sharedPathAn, "phyloseq", "unite-ver8-taxonomy_99_02.02.2019.qza", sep = "/"),
             " --input-format HeaderlessTSVTaxonomyFormat ",
             " && conda deactivate ", sep = "")
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

```{r}
# Train the classifier
prefix <- "qiimeTrainUnite"
cmd <- paste("conda activate qiime2-2020.8 && ",
             " qiime feature-classifier fit-classifier-naive-bayes ",
             " --i-reference-reads ", paste(sharedPathAn, "phyloseq", "unite-ver8_99_02.02.2019.qza", sep = "/"), 
             " --i-reference-taxonomy ", paste(sharedPathAn, "phyloseq", "unite-ver8-taxonomy_99_02.02.2019.qza", sep = "/"),
             " --o-classifier ", paste(sharedPathAn, "phyloseq", "unite-ver8-classifier_99_02.02.2019.qza", sep = "/"),
             " && conda deactivate ", sep = "")
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

```{r}
prefix <- "qiimeClassifyFeature"
cmd <- paste("conda activate qiime2-2020.8 && ",
             " qiime feature-classifier classify-sklearn ",
             " --i-classifier ", paste(sharedPathAn, "phyloseq", "unite-ver8-classifier_99_02.02.2019.qza", sep = "/"),
             " --i-reads ", paste(qiime2Dir, "rep-seqs-dada2.qza", sep = "/"),
             " --o-classification ", paste(qiime2Dir, "taxonomy-single-end.qza", sep = "/"),
             " && conda deactivate ", sep = "")
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```
```{r}
prefix <- "qiimeFeatureExport"
cmd <- paste("conda activate qiime2-2020.8 && ",
             " qiime tools export ",
             " --input-path ", paste(qiime2Dir, "taxonomy-single-end.qza", sep = "/"),
             " --output-path ", paste(sharedPathAn, "phyloseq", sep = "/"),
             " && conda deactivate ", sep = "")
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

To get the ASV/OTU tablewith taxonomy column at the end, do we combine the otu_table.tsv and taxonomy.tsv together by feature ID row?
```{r}
list.files(path = paste(sharedPathAn, "phyloseq", sep = "/"))
library(data.table)
library(phyloseq)
otuTbl <- fread(paste(sharedPathAn, "phyloseq", "otu_table.tsv", sep = "/"))
taxTbl <- fread(paste(sharedPathAn, "phyloseq", "taxonomy.tsv", sep = "/"))


# Open the taxonomy and change the header. When you open it, youâ€™ll see the header looks like this: 
# Feature ID	Taxon	Confidence
# where the spaces are tabs. You need to change it to this:
# otu-id	taxonomy	Confidence

setnames(taxTbl, "Feature ID", "otu-id")
setnames(taxTbl, "Taxon", "taxonomy")

setnames(otuTbl, "V1", "otu-id")

setkey(otuTbl, "otu-id")
setkey(taxTbl, "otu-id")

otuTaxTbl <- merge(otuTbl, taxTbl)
otuTaxTbl$Confidence <- NULL

write.table(otuTaxTbl, file = paste(sharedPathAn, "otuTax_table.tsv", sep = "/"), 
            quote = FALSE, sep = "\t", row.names = FALSE, col.names = TRUE)
```

```{r}
library("RAM")
dir.create(paste(sharedPathAn, "taxFill", sep = "/"), showWarnings = TRUE, recursive    = FALSE)
taxFillPath <- paste(sharedPathAn, "taxFill", sep = "/")

temp <- read.table(paste(sharedPathAn, "otuTax_table.tsv", sep = "/"), sep = "\t", header = TRUE, dec = ".", 
                   comment.char = "", quote = "", stringsAsFactors = TRUE,
                   as.is = TRUE, colClasses=c("taxonomy"="character"))

row.names(temp) <- temp$otu.id
temp$otu.id <- NULL

temp <- tax.fill(temp, downstream=TRUE)

write.table(temp, file=paste(taxFillPath, "ITS1F.table.taxfill.tsv", sep = "/"),
            append = FALSE, sep = "\t", row.names = FALSE, quote = FALSE)
```


Create diversity directory and path. List your datasets for diversity indexes. Adds a bunch of columns in a new diversity metadata file.
Indices obtained (in this specific order) are: Spec Number,  Simpson data,  Inv simpson data,	Shannon data,	Simpson eveness,	Shannon eveness,	Simpson true diversity,	shannon true diversity,	chao,	ACE.
```{r}
dir.create(paste(sharedPathAn, "diversity", sep = "/"), showWarnings = TRUE, recursive = FALSE)
diversityPath <- paste(sharedPathAn, "diversity", sep = "/")

metaTemp <- metadataITSF
rownames(metaTemp) <- colnames(temp)[-ncol(temp)] #seems to work
temp2 <- OTU.diversity(list(data=temp), metaTemp)
write.table(temp2, file=paste(diversityPath, "OWPlate1_ITS1F.meta.div.tsv", sep = "/"),
            append = FALSE, sep = "\t", row.names = FALSE, quote=FALSE)
```

Save image:
```{r}
save.image(paste(imageDirPath, baseImage, sep = ""))
```

